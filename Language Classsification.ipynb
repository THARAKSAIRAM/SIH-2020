{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/THARAKSAIRAM/SIH-2020/blob/master/Language%20Classsification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoToBMXqNTwo",
        "colab_type": "code",
        "outputId": "c664645c-e312-4dba-e680-9dc2c271b9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6IzvRpN1QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSKpkviTOi5f",
        "colab_type": "code",
        "outputId": "bab4d207-c3da-4075-a1db-6161db0082f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "pip install python_speech_features\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5889 sha256=4c72d2daf1758365f03af91bef242d7cdf10685d5317ba7bb88b55b63c2f3ded\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvSe_D1QQfD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from python_speech_features import mfcc,delta,logfbank "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wdm6Q95RzMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import scipy.io.wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import wave\n",
        "import contextlib\n",
        "from scipy.fftpack import dct\n",
        "import scipy.io.wavfile as wav"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InimuT0TW727",
        "colab_type": "code",
        "outputId": "24e3db00-057d-4018-d57a-d313c9d28c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras import applications\n",
        "from keras.layers import GlobalAveragePooling2D,Dropout,Dense,BatchNormalization,Activation,AveragePooling2D,Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTytRI74SGYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_emphasis = 0.97\n",
        "frame_size = 0.025\n",
        "frame_stride = 0.01\n",
        "NFFT = 512\n",
        "nfilt = 40\n",
        "num_ceps = 12\n",
        "cep_lifter =22"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIR3PbzqSLkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def length_audio(folder_name,file_name):\n",
        "  file_path='/content/'+str(folder_name)+\"/\"+str(file_name)\n",
        "  sample_rate, signal = scipy.io.wavfile.read(file_path)\n",
        "  with contextlib.closing(wave.open(file_path,'r')) as f:\n",
        "      frames = f.getnframes()\n",
        "      rate = f.getframerate()\n",
        "      duration = frames / float(rate)\n",
        "  return int(duration)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6SDfjbfSngz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mfcc(folder_name,file_name,start_point):\n",
        "    file_path ='/content/'+str(folder_name)+\"/\"+str(file_name)\n",
        "    sample_rate, signal = scipy.io.wavfile.read(file_path)\n",
        "    signal = signal[start_point:int(start_point+2 * sample_rate)]   #framing to 2 seconds\n",
        "    emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1]) #pre-emphasis\n",
        "    frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\n",
        "    signal_length = len(emphasized_signal)\n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\n",
        "    pad_signal_length = num_frames * frame_step + frame_length\n",
        "    z = numpy.zeros((pad_signal_length - signal_length))\n",
        "    pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
        "    indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
        "    frames = pad_signal[indices.astype(numpy.int32, copy=False)]\n",
        "    #After slicing the signal into frames, we apply a window function such as the Hamming window\n",
        "    frames *= numpy.hamming(frame_length)  #hamming window\n",
        "    mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\n",
        "    pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum\n",
        "    low_freq_mel = 0\n",
        "    high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\n",
        "    mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\n",
        "    hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\n",
        "    bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\n",
        "\n",
        "    fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\n",
        "    for m in range(1, nfilt + 1):\n",
        "        f_m_minus = int(bin[m - 1])   # left\n",
        "        f_m = int(bin[m])             # center\n",
        "        f_m_plus = int(bin[m + 1])    # right\n",
        "\n",
        "        for k in range(f_m_minus, f_m):\n",
        "            fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\n",
        "        for k in range(f_m, f_m_plus):\n",
        "            fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\n",
        "\n",
        "    filter_banks = numpy.dot(pow_frames, fbank.T)\n",
        "    filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\n",
        "    filter_banks = 20 * numpy.log10(filter_banks)  # dB\n",
        "    mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13\n",
        "    (nframes, ncoeff) = mfcc.shape\n",
        "    n = numpy.arange(ncoeff)\n",
        "    lift = 1 + (cep_lifter / 2) * numpy.sin(numpy.pi * n / cep_lifter)\n",
        "    mfcc *= lift  #*\n",
        "    \n",
        "    filter_banks -= (numpy.mean(filter_banks, axis=0) + 1e-8)\n",
        "    mfcc -= (numpy.mean(mfcc, axis=0) + 1e-8)\n",
        "    \n",
        "    return filter_banks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrRCkOFiV276",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  base_model=applications.resnet50.ResNet50(weights=None,include_top=False,input_shape = (40,40,1))\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = AveragePooling2D(pool_size=2)(x)\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(11,activation='softmax',kernel_initializer='he_normal')(y)\n",
        "  model=Model(inputs=base_model.input,outputs=outputs)\n",
        "  adam=Adam(lr=0.0001)\n",
        "  model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9SV-Rq0TG9r",
        "colab_type": "code",
        "outputId": "4f20ed0a-d51e-45a9-bb17-59a5b9bf874e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = create_model()\n",
        "model.load_weights('drive/My Drive/language_classificationII.h5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d40d7816c616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/language_classificationII.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1217\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 7 layers into a model with 108 layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gj8KE_7Yx1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(targ):\n",
        "    accents = ['bengali','dogri','gujarathi','hindi','malayalam','manipuri','marathi','odisha','tamil','telugu','urdu']\n",
        "    np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    #np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    l=[]\n",
        "    out_len = len(targ)\n",
        "    in_len = len(targ[0])\n",
        "    for i in range(in_len):\n",
        "        sumi = 0\n",
        "        for j in range(out_len):\n",
        "            sumi+=targ[j][i]\n",
        "        l.append(sumi)\n",
        "    print(l)\n",
        "    maximum = -1\n",
        "    max_ind = -1\n",
        "    for i in range(len(l)):\n",
        "        if(l[i] > maximum):\n",
        "            maximum = l[i]\n",
        "            max_ind = i+1\n",
        "    # print(maximum, max_ind)\n",
        "    print(\"Accent: \",accents[max_ind-1])\n",
        "    for i in l:\n",
        "        if i!=0:\n",
        "            per = (i/float(out_len))*100\n",
        "            if(per>1):\n",
        "                print(\"{1:.2f}% -> {0}\".format(accents[l.index(i)],per))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_oeeaEdV14N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Pre_final_data(folder,files):\n",
        "    index=0\n",
        "    \n",
        "    mfcc=[]\n",
        "    target=[]\n",
        "    mfcc_len=length_audio(folder,files)\n",
        "    data_dic = np.zeros((1+mfcc_len//2,398,40))\n",
        "    for i in range(0,mfcc_len,2):\n",
        "        \n",
        "        mfcc = create_mfcc(folder,files,i)\n",
        "        for j in range(len(mfcc)):\n",
        "              for k in range(len(mfcc[j])):\n",
        "                data_dic[index][j][k] = mfcc[j][k]\n",
        "        index += 1\n",
        "        #target.append(mfcc)\n",
        "    #target=np.asarray()\n",
        "    \n",
        "    data_dic_reshaped = data_dic.reshape(data_dic.shape[0],398,40,1)\n",
        "    targ=model.predict(data_dic_reshaped)    \n",
        "    print(targ)\n",
        "    prediction(targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m-P0uOHRaiQ",
        "colab_type": "code",
        "outputId": "84a40474-7f0d-4b5f-a661-faa98349c003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "folder='drive/My Drive/testing'\n",
        "file='test_krish.wav'\n",
        "print(Pre_final_data(folder,file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]]\n",
            "[2.2084815313322403e-11, 7.999998688697815, 4.4749546290745457e-08, 3.181414143628783e-12, 4.123314560899871e-07, 1.3797249069158815e-12, 5.236921528583248e-14, 7.840901155020674e-07, 4.7221957107507196e-15, 7.553454715002184e-12, 8.675708823344815e-16]\n",
            "Accent:  dogri\n",
            "100.00% -> dogri\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egWZgfJDY9R5",
        "colab_type": "code",
        "outputId": "192a8f63-96d8-4a1e-bfd5-be6c7bb5c4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23650\n",
            "23650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m-8QmAQYDJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZmJe58mYMcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhTFgNNYP3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap98HDZQYZGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CgMpV11Yb67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFGsUQBZYeRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djenH7ciDWvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save('language_classification.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RB8SJx1EtVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = X_test.reshape(X_test.shape[0],398,40,1)\n",
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04mjira1K8Rd",
        "colab_type": "code",
        "outputId": "090dd51c-7919-4c38-ea16-999783252450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(y_pred[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.1934635e-05 9.9977022e-01 1.1724382e-07 3.0121672e-08 8.0185441e-07\n",
            " 2.6898798e-07 4.6595054e-05 2.0830630e-05 3.5584791e-05 1.6739827e-07\n",
            " 1.0348346e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6C_dKlJF-Cd",
        "colab_type": "code",
        "outputId": "c11e4e23-da20-42c6-8baf-a41cb454e7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# print(accuracy_score(Y_test, y_pred))\n",
        "acc=0\n",
        "for i in range(len(Y_test)):\n",
        "  count=0\n",
        "  for j in range(len(Y_test[i])):\n",
        "    if(Y_test[i][j]==round(y_pred[i][j],0)):\n",
        "      count+=1\n",
        "  if(count==11):\n",
        "    acc+=1\n",
        "print(\"Accuracy is\",(acc/len(Y_test))*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 99.35734821579571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AEKK2Sv_nC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########Testing manual#############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMLNOE_Q_qu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D,Dropout,Dense,BatchNormalization,Activation,AveragePooling2D,Flatten\n",
        "from keras.models import Model\n",
        "from keras import applications\n",
        "from keras import applications\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEvPxXSX_nMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  base_model=applications.resnet50.ResNet50(weights=None,include_top=False,input_shape = (40,40,1))\n",
        "  x = base_model.output\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = AveragePooling2D(pool_size=2)(x)\n",
        "  y = Flatten()(x)\n",
        "  outputs = Dense(11,activation='softmax',kernel_initializer='he_normal')(y)\n",
        "  rnet=Model(inputs=base_model.input,outputs=outputs)\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(1,(3,3),padding='same',activation = 'relu',input_shape = (398,40,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "  model.add(Convolution2D(1, 2, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\n",
        "  model.add(rnet)\n",
        "  adam=Adam(lr=0.0001)\n",
        "  model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN5IxfofAdFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(targ):\n",
        "    accents = ['bengali','dogri','gujarathi','hindi','malayalam','manipuri','marathi','odisha','tamil','telugu','urdu']\n",
        "    np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    #np.set_printoptions(formatter={'float_kind':'{:.1f}'.format})\n",
        "    l=[]\n",
        "    out_len = len(targ)\n",
        "    in_len = len(targ[0])\n",
        "    for i in range(in_len):\n",
        "        sumi = 0\n",
        "        for j in range(out_len):\n",
        "            sumi+=targ[j][i]\n",
        "        l.append(sumi)\n",
        "    print(l)\n",
        "    maximum = -1\n",
        "    max_ind = -1\n",
        "    for i in range(len(l)):\n",
        "        if(l[i] > maximum):\n",
        "            maximum = l[i]\n",
        "            max_ind = i+1\n",
        "    # print(maximum, max_ind)\n",
        "    print(\"Accent: \",accents[max_ind-1])\n",
        "    for i in l:\n",
        "        if i!=0:\n",
        "            per = (i/float(out_len))*100\n",
        "            if(per>1):\n",
        "                print(\"{1:.2f}% -> {0}\".format(accents[l.index(i)],per))\n",
        "                print(accents[l.index(i)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntX_9VbD_s7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Pre_final_data(folder,files):\n",
        "    index=0\n",
        "    data_dic = np.zeros((23650,398,40))\n",
        "    mfcc=[]\n",
        "    target=[]\n",
        "    mfcc_len=length_audio(folder,files)\n",
        "    \n",
        "    for i in range(0,mfcc_len,2):\n",
        "        \n",
        "        mfcc = create_mfcc(folder,files,i)\n",
        "        for j in range(len(mfcc)):\n",
        "              for k in range(len(mfcc[j])):\n",
        "                data_dic[index][j][k] = mfcc[j][k]\n",
        "        index += 1\n",
        "        #target.append(mfcc)\n",
        "    #target=np.asarray()\n",
        "    \n",
        "    data_dic_reshaped = data_dic.reshape(data_dic.shape[0],398,40,1)\n",
        "    md = create_model()\n",
        "    md.load_weights('drive/My Drive/language_classificationII.h5')\n",
        "    targ=md.predict(data_dic_reshaped)    \n",
        "    print(targ)\n",
        "    prediction(targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d1qZO_hN-B9",
        "colab_type": "code",
        "outputId": "c107346d-c698-4984-d378-e939d64ec148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "folder='drive/My Drive/testing'\n",
        "file='test_krish.wav'\n",
        "print(Pre_final_data(folder,file))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (2, 1), activation=\"relu\", use_bias=False)`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 1), activation=\"relu\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 1), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 1), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (3, 1), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 0.0 ... 0.0 0.0 1.0]\n",
            " [0.0 0.0 0.0 ... 0.0 0.0 1.0]\n",
            " [0.0 0.0 0.0 ... 0.0 0.0 1.0]\n",
            " ...\n",
            " [0.2 0.8 0.0 ... 0.0 0.0 0.0]\n",
            " [0.2 0.8 0.0 ... 0.0 0.0 0.0]\n",
            " [0.2 0.8 0.0 ... 0.0 0.0 0.0]]\n",
            "[3994.8042896813554, 19253.42237205195, 8.167068315153939, 42.37557720416251, 0.4861113382798976, 6.550523406867796, 0.18227765817664476, 0.31076717014263977, 147.4658810468468, 1.331657541471941, 194.90236069448292]\n",
            "Accent:  dogri\n",
            "16.89% -> bengali\n",
            "bengali\n",
            "81.41% -> dogri\n",
            "dogri\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBT987qN-r6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc3E_5ssOSTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "2cb1a15f-4ece-41bb-fb7c-200c4d88559a"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-8958d433c794>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))model.add(Convolution2D(1, 3, 1, activation='relu',use_bias=False))\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxynOMxN_cJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}